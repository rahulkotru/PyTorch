{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import tarfile\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: .\\cifar10.tgz\n"
     ]
    }
   ],
   "source": [
    "dataset_url = \"https://s3.amazonaws.com/fast-ai-imageclas/cifar10.tgz\"\n",
    "download_url(dataset_url, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tarfile.open('./cifar10.tgz', 'r:gz') as tar:\n",
    "    tar.extractall(path='./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test', 'train']\n",
      "['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
     ]
    }
   ],
   "source": [
    "data_dir = './data/cifar10'\n",
    "\n",
    "print(os.listdir(data_dir))\n",
    "classes = os.listdir(data_dir + \"/train\")\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of training examples for airplanes: 5000\n",
      "['0001.png', '0002.png', '0003.png', '0004.png', '0005.png']\n"
     ]
    }
   ],
   "source": [
    "airplane_files = os.listdir(data_dir + \"/train/airplane\")\n",
    "print('No. of training examples for airplanes:', len(airplane_files))\n",
    "print(airplane_files[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of test examples for ship: 1000\n",
      "['0001.png', '0002.png', '0003.png', '0004.png', '0005.png']\n"
     ]
    }
   ],
   "source": [
    "ship_test_files = os.listdir(data_dir + \"/test/ship\")\n",
    "print(\"No. of test examples for ship:\", len(ship_test_files))\n",
    "print(ship_test_files[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=ImageFolder(data_dir+'/train',transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 32, 32]) 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7922, 0.7922, 0.8000,  ..., 0.8118, 0.8039, 0.7961],\n",
       "         [0.8078, 0.8078, 0.8118,  ..., 0.8235, 0.8157, 0.8078],\n",
       "         [0.8235, 0.8275, 0.8314,  ..., 0.8392, 0.8314, 0.8235],\n",
       "         ...,\n",
       "         [0.8549, 0.8235, 0.7608,  ..., 0.9529, 0.9569, 0.9529],\n",
       "         [0.8588, 0.8510, 0.8471,  ..., 0.9451, 0.9451, 0.9451],\n",
       "         [0.8510, 0.8471, 0.8510,  ..., 0.9373, 0.9373, 0.9412]],\n",
       "\n",
       "        [[0.8000, 0.8000, 0.8078,  ..., 0.8157, 0.8078, 0.8000],\n",
       "         [0.8157, 0.8157, 0.8196,  ..., 0.8275, 0.8196, 0.8118],\n",
       "         [0.8314, 0.8353, 0.8392,  ..., 0.8392, 0.8353, 0.8275],\n",
       "         ...,\n",
       "         [0.8510, 0.8196, 0.7608,  ..., 0.9490, 0.9490, 0.9529],\n",
       "         [0.8549, 0.8471, 0.8471,  ..., 0.9412, 0.9412, 0.9412],\n",
       "         [0.8471, 0.8431, 0.8471,  ..., 0.9333, 0.9333, 0.9333]],\n",
       "\n",
       "        [[0.7804, 0.7804, 0.7882,  ..., 0.7843, 0.7804, 0.7765],\n",
       "         [0.7961, 0.7961, 0.8000,  ..., 0.8039, 0.7961, 0.7882],\n",
       "         [0.8118, 0.8157, 0.8235,  ..., 0.8235, 0.8157, 0.8078],\n",
       "         ...,\n",
       "         [0.8706, 0.8392, 0.7765,  ..., 0.9686, 0.9686, 0.9686],\n",
       "         [0.8745, 0.8667, 0.8627,  ..., 0.9608, 0.9608, 0.9608],\n",
       "         [0.8667, 0.8627, 0.8667,  ..., 0.9529, 0.9529, 0.9529]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img,label=dataset[0]\n",
    "print(img.shape,label)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e76a616202f8a8b2a32c1eadd0322a3f472543fa8b4cbf2c2d09118407aaec5c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('pytorch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
